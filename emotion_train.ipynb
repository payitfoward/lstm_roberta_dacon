{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43140f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, TrainingArguments, Trainer\n",
    "from mkdataset import EmotionDataset, TestDataset\n",
    "from datasets import load_metric, load_dataset\n",
    "from classifier import RobertaForSequenceClassification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utils import set_allseed\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7eb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "batch_size = 32\n",
    "save_steps = 103\n",
    "set_allseed(seed)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "gpu = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137027c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    f1 = load_metric(\"f1\")\n",
    "    references = pred.label_ids\n",
    "    predictions = pred.predictions.argmax(axis=1)\n",
    "    metric = f1.compute(predictions=predictions, references=references, average=\"micro\")\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd683a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da72955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"문장\",\"극성\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad490eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_function = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "type_config = AutoConfig.from_pretrained(\"klue/roberta-base\")\n",
    "type_config.num_labels = len(train_df.극성.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938d37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output_type\",\n",
    "    seed=seed,\n",
    "    save_total_limit=2,\n",
    "    save_steps = save_steps,\n",
    "    num_train_epochs = 5,\n",
    "    learning_rate= 1e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    weight_decay=1e-4,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps = save_steps,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    metric_for_best_model = \"eval_f1\",\n",
    "    eval_steps = save_steps,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "test_dataset = TestDataset(data=test_df, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3c7f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['lstm.weight_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'roberta.pooler.dense.weight', 'lstm.bias_ih_l1', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1', 'lstm.weight_hh_l0', 'lstm.weight_ih_l0', 'lstm.bias_ih_l1_reverse', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_hh_l0', 'lstm.bias_hh_l0_reverse', 'lstm.bias_ih_l0', 'classifier.bias', 'lstm.weight_hh_l1', 'lstm.weight_hh_l0_reverse', 'classifier.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 13232\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 515\n",
      "  Number of trainable parameters = 134240259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ceb8a61907a451db040bf08a85dcd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3309\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1503, 'learning_rate': 8e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf1c272af5149309e0defd3f1cff44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-103\n",
      "Configuration saved in ./output_type\\checkpoint-103\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10345058888196945, 'eval_f1': 0.9697793895436688, 'eval_runtime': 9.9335, 'eval_samples_per_second': 333.115, 'eval_steps_per_second': 10.47, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-103\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-206] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3309\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0879, 'learning_rate': 6e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422fbfdd730e43a3a9ed632d00e868ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-206\n",
      "Configuration saved in ./output_type\\checkpoint-206\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08054681867361069, 'eval_f1': 0.9746146872166818, 'eval_runtime': 9.4292, 'eval_samples_per_second': 350.932, 'eval_steps_per_second': 11.03, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-206\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-515] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3309\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0685, 'learning_rate': 4e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e262abf6cebe43a9855aac724bb1d819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-309\n",
      "Configuration saved in ./output_type\\checkpoint-309\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09877751767635345, 'eval_f1': 0.9737080689029919, 'eval_runtime': 9.5382, 'eval_samples_per_second': 346.92, 'eval_steps_per_second': 10.903, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-309\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-103] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3309\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0464, 'learning_rate': 2e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4754f9404e5346b089797028b2bf4239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-412\n",
      "Configuration saved in ./output_type\\checkpoint-412\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10229171812534332, 'eval_f1': 0.9737080689029919, 'eval_runtime': 9.2947, 'eval_samples_per_second': 356.008, 'eval_steps_per_second': 11.189, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-412\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-309] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3309\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0211, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d98a7acf5f8406d87e05103b7211f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-515\n",
      "Configuration saved in ./output_type\\checkpoint-515\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11457707732915878, 'eval_f1': 0.9721970383801752, 'eval_runtime': 10.1252, 'eval_samples_per_second': 326.807, 'eval_steps_per_second': 10.271, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-515\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-412] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./output_type\\checkpoint-206 (score: 0.9746146872166818).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1086.3239, 'train_samples_per_second': 60.903, 'train_steps_per_second': 0.474, 'train_loss': 0.07483272691374844, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0942759a7a14e7fb5afa3bbcc626127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Administrator/.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\67dd433d36ebc66a42c9aaa85abcf8d2620e41d9\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['lstm.weight_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'roberta.pooler.dense.weight', 'lstm.bias_ih_l1', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1', 'lstm.weight_hh_l0', 'lstm.weight_ih_l0', 'lstm.bias_ih_l1_reverse', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_hh_l0', 'lstm.bias_hh_l0_reverse', 'lstm.bias_ih_l0', 'classifier.bias', 'lstm.weight_hh_l1', 'lstm.weight_hh_l0_reverse', 'classifier.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 13233\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 515\n",
      "  Number of trainable parameters = 134240259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8574d948ef7248d3a90c778fd4e984d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1591, 'learning_rate': 8e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f10630d9b584f47a641d750fbef1691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-103\n",
      "Configuration saved in ./output_type\\checkpoint-103\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09473810344934464, 'eval_f1': 0.9737001209189843, 'eval_runtime': 14.5632, 'eval_samples_per_second': 227.148, 'eval_steps_per_second': 7.141, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-103\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-206] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1072, 'learning_rate': 6e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e06fc2f54ad4e7695a21dfc5b4b6df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-206\n",
      "Configuration saved in ./output_type\\checkpoint-206\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12215959280729294, 'eval_f1': 0.9703748488512697, 'eval_runtime': 14.6521, 'eval_samples_per_second': 225.769, 'eval_steps_per_second': 7.098, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-206\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-515] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0875, 'learning_rate': 4e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8a709d348c4309a825aa0d0a72acb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-309\n",
      "Configuration saved in ./output_type\\checkpoint-309\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09377638250589371, 'eval_f1': 0.9761185006045949, 'eval_runtime': 15.1588, 'eval_samples_per_second': 218.224, 'eval_steps_per_second': 6.861, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-309\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-103] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0677, 'learning_rate': 2e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93d074b3d48443791b563df1be0cd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-412\n",
      "Configuration saved in ./output_type\\checkpoint-412\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09576389193534851, 'eval_f1': 0.9715840386940748, 'eval_runtime': 14.9043, 'eval_samples_per_second': 221.95, 'eval_steps_per_second': 6.978, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-412\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-206] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0501, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acd518e07ea4e96b458269378b4ceed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-515\n",
      "Configuration saved in ./output_type\\checkpoint-515\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0874306932091713, 'eval_f1': 0.9737001209189843, 'eval_runtime': 15.4846, 'eval_samples_per_second': 213.631, 'eval_steps_per_second': 6.716, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-515\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-412] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./output_type\\checkpoint-309 (score: 0.9761185006045949).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1122.7656, 'train_samples_per_second': 58.93, 'train_steps_per_second': 0.459, 'train_loss': 0.09432319807774812, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fe835ccae546cfaf32c5baba4a2f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Administrator/.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\67dd433d36ebc66a42c9aaa85abcf8d2620e41d9\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['lstm.weight_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'roberta.pooler.dense.weight', 'lstm.bias_ih_l1', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1', 'lstm.weight_hh_l0', 'lstm.weight_ih_l0', 'lstm.bias_ih_l1_reverse', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_hh_l0', 'lstm.bias_hh_l0_reverse', 'lstm.bias_ih_l0', 'classifier.bias', 'lstm.weight_hh_l1', 'lstm.weight_hh_l0_reverse', 'classifier.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 13233\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 515\n",
      "  Number of trainable parameters = 134240259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8c9e44972648abaaafb24c16e6b4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.161, 'learning_rate': 8e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fd89f9f42b41ed8436f9c6cc99848c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-103\n",
      "Configuration saved in ./output_type\\checkpoint-103\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13324978947639465, 'eval_f1': 0.9664449818621523, 'eval_runtime': 11.1559, 'eval_samples_per_second': 296.526, 'eval_steps_per_second': 9.322, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-103\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-309] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0887, 'learning_rate': 6e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e8855c5a214b6ea1de1c28e0ee87d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-206\n",
      "Configuration saved in ./output_type\\checkpoint-206\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11059308052062988, 'eval_f1': 0.968863361547763, 'eval_runtime': 10.8247, 'eval_samples_per_second': 305.598, 'eval_steps_per_second': 9.608, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-206\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-515] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0723, 'learning_rate': 4e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1af1f280b540e397af300582e403a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-309\n",
      "Configuration saved in ./output_type\\checkpoint-309\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08114301413297653, 'eval_f1': 0.9764207980652962, 'eval_runtime': 10.999, 'eval_samples_per_second': 300.756, 'eval_steps_per_second': 9.455, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-309\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-103] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0539, 'learning_rate': 2e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d0fd9b2d784cb2826bebf8874b1d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-412\n",
      "Configuration saved in ./output_type\\checkpoint-412\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09198292344808578, 'eval_f1': 0.9730955259975816, 'eval_runtime': 10.7134, 'eval_samples_per_second': 308.773, 'eval_steps_per_second': 9.708, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-412\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-206] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0374, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1210da26ded40fe9a0a124f996e4376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-515\n",
      "Configuration saved in ./output_type\\checkpoint-515\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09165237098932266, 'eval_f1': 0.9743047158403869, 'eval_runtime': 10.8555, 'eval_samples_per_second': 304.731, 'eval_steps_per_second': 9.58, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-515\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-412] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./output_type\\checkpoint-309 (score: 0.9764207980652962).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1101.5378, 'train_samples_per_second': 60.066, 'train_steps_per_second': 0.468, 'train_loss': 0.08266847712322346, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64d42ea0c9945c492644b9d8dd8d3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Administrator/.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\67dd433d36ebc66a42c9aaa85abcf8d2620e41d9\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['lstm.weight_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'roberta.pooler.dense.weight', 'lstm.bias_ih_l1', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1', 'lstm.weight_hh_l0', 'lstm.weight_ih_l0', 'lstm.bias_ih_l1_reverse', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_hh_l0', 'lstm.bias_hh_l0_reverse', 'lstm.bias_ih_l0', 'classifier.bias', 'lstm.weight_hh_l1', 'lstm.weight_hh_l0_reverse', 'classifier.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 13233\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 515\n",
      "  Number of trainable parameters = 134240259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c874b3f673418681e20c288da19b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1537, 'learning_rate': 8e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49e4f3ed64a4c4099c9a288d3403257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-103\n",
      "Configuration saved in ./output_type\\checkpoint-103\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11104735732078552, 'eval_f1': 0.9727932285368803, 'eval_runtime': 19.6748, 'eval_samples_per_second': 168.134, 'eval_steps_per_second': 5.286, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-103\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-309] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0953, 'learning_rate': 6e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34234f10da104eb1af514b682d464a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-206\n",
      "Configuration saved in ./output_type\\checkpoint-206\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09331850707530975, 'eval_f1': 0.973397823458283, 'eval_runtime': 19.4753, 'eval_samples_per_second': 169.857, 'eval_steps_per_second': 5.34, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-206\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-515] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0739, 'learning_rate': 4e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e42329773b41cbaa598ba6e4bde5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-309\n",
      "Configuration saved in ./output_type\\checkpoint-309\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08479707688093185, 'eval_f1': 0.973397823458283, 'eval_runtime': 19.3907, 'eval_samples_per_second': 170.598, 'eval_steps_per_second': 5.363, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-309\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-103] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0543, 'learning_rate': 2e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65540ce7eebc4d34bae4546396cc347a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-412\n",
      "Configuration saved in ./output_type\\checkpoint-412\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09347149729728699, 'eval_f1': 0.9737001209189843, 'eval_runtime': 19.5734, 'eval_samples_per_second': 169.005, 'eval_steps_per_second': 5.313, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-412\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-206] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0332, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb70dd7e3014c8f92d97b6beb986094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-515\n",
      "Configuration saved in ./output_type\\checkpoint-515\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09528342634439468, 'eval_f1': 0.9721886336154775, 'eval_runtime': 19.179, 'eval_samples_per_second': 172.481, 'eval_steps_per_second': 5.423, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-515\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-309] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./output_type\\checkpoint-412 (score: 0.9737001209189843).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 897.7821, 'train_samples_per_second': 73.698, 'train_steps_per_second': 0.574, 'train_loss': 0.0821030588983332, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57ce45818c946e1b3f922584568cd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Administrator/.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\67dd433d36ebc66a42c9aaa85abcf8d2620e41d9\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['lstm.weight_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'roberta.pooler.dense.weight', 'lstm.bias_ih_l1', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1', 'lstm.weight_hh_l0', 'lstm.weight_ih_l0', 'lstm.bias_ih_l1_reverse', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_hh_l0', 'lstm.bias_hh_l0_reverse', 'lstm.bias_ih_l0', 'classifier.bias', 'lstm.weight_hh_l1', 'lstm.weight_hh_l0_reverse', 'classifier.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 13233\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 515\n",
      "  Number of trainable parameters = 134240259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9ed30c3e9b43f785d30d6bed77561e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.146, 'learning_rate': 8e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299e515e21d4485397afe2ca63d878bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-103\n",
      "Configuration saved in ./output_type\\checkpoint-103\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09212537109851837, 'eval_f1': 0.9727932285368803, 'eval_runtime': 9.4335, 'eval_samples_per_second': 350.667, 'eval_steps_per_second': 11.025, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-103\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-412] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0812, 'learning_rate': 6e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c410318ebb4d0ca5da784a644b8d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-206\n",
      "Configuration saved in ./output_type\\checkpoint-206\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0845782533288002, 'eval_f1': 0.9703748488512697, 'eval_runtime': 9.1192, 'eval_samples_per_second': 362.752, 'eval_steps_per_second': 11.405, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-206\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-515] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0623, 'learning_rate': 4e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea8b78d85a34400be206143b225f5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-309\n",
      "Configuration saved in ./output_type\\checkpoint-309\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07763124257326126, 'eval_f1': 0.9758162031438936, 'eval_runtime': 9.5484, 'eval_samples_per_second': 346.446, 'eval_steps_per_second': 10.892, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-309\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-103] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0406, 'learning_rate': 2e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2b46caa2ac4e23955b316c9c5b8297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-412\n",
      "Configuration saved in ./output_type\\checkpoint-412\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09087077528238297, 'eval_f1': 0.975211608222491, 'eval_runtime': 9.1231, 'eval_samples_per_second': 362.594, 'eval_steps_per_second': 11.4, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-412\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-206] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3308\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0207, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966cd8dd5ed407394c025db3e5c7ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_type\\checkpoint-515\n",
      "Configuration saved in ./output_type\\checkpoint-515\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1144118383526802, 'eval_f1': 0.9746070133010882, 'eval_runtime': 9.6107, 'eval_samples_per_second': 344.201, 'eval_steps_per_second': 10.821, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./output_type\\checkpoint-515\\pytorch_model.bin\n",
      "Deleting older checkpoint [output_type\\checkpoint-412] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./output_type\\checkpoint-309 (score: 0.9758162031438936).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1093.3356, 'train_samples_per_second': 60.517, 'train_steps_per_second': 0.471, 'train_loss': 0.07015352804683944, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2fefce68084713bf00c45d6e8c241a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit = 0\n",
    "for i, (train_index, test_index) in enumerate(kfold_function.split(train_df[\"문장\"],train_df[\"극성\"])):\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"klue/roberta-base\", config=type_config)\n",
    "    train_corpus, valid_corpus = train_df[\"문장\"][train_index], train_df[\"문장\"][test_index]\n",
    "    train_label, valod_label = train_df[\"극성\"][train_index], train_df[\"극성\"][test_index]\n",
    "    fold_train = pd.concat([train_corpus, train_label], axis =1)\n",
    "    fold_valid = pd.concat([valid_corpus, valod_label], axis =1)\n",
    "    train_dataset = EmotionDataset(data=fold_train, tokenizer=tokenizer)\n",
    "    valid_dataset = EmotionDataset(data=fold_valid, tokenizer=tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    logit += trainer.predict(test_dataset).predictions / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15480153",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(logit.argmax(axis=1).tolist(), columns=[\"emotion\"])\n",
    "test_df_result = pd.concat([test_df,result],axis=1, ignore_index=True)\n",
    "test_df_result.to_csv(\"result_emotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b9432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 18:44:54) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29653ce4d73fa5f169ecc06a93e234b4ee76974eb34f5783d536006096322e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
